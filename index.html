<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Ayse Demir Portfolio</title>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Roboto+Slab:wght@400;600;700&display=swap" rel="stylesheet">
<style>
  :root {
    --background-color: #fff;
    --text-color: #262525;
    --font-family: Arial, "Inter", system-ui, -apple-system, Segoe UI, Roboto, "Helvetica Neue", Helvetica, "Noto Sans", "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
    --font-weight: 80px;
    --rule: #e8e8e8;
    --left-col: 220px;        /* adjust if you want bigger/smaller canvases */
  }

  * { box-sizing: border-box; }
  body {
    margin: 0;
    background: var(--background-color);
    color: var(--text-color);
    font-family: var(--font-family);
    display: flex;
    flex-direction: column;
    align-items: center;
    padding: 1rem;
    min-height: 100vh;
  }
  h1 {
    margin: 0 0 1rem;
    font-weight: var(--font-weight);
    color: #111;
    font-size: 0.7rem;
    width: 100%;
    max-width: 900px;
    text-align: left;
  }
 
 p {
  line-height: 1.5; /* Try 1.65–1.75 for best readability */
}

  .content li {
  line-height: 1.5; /* Try 1.65–1.75 for best readability */
  font-size: 0.8rem;
}

  /* Details/summary */
  details { width: 100%; max-width: 900px; margin: 0.5rem 0; font-size: 0.8rem; color: var(--text-color); font-weight: var(--font-weight); }
  summary {
    list-style: none; position: relative; cursor: pointer; outline: none;
    font-size: 0.8rem; font-weight: 700; border: none; padding: 0.5rem 1rem 0.5rem 2rem;
    border-radius: 0.5rem; background: var(--background-color); color: #262525;
  }
  summary::before { content: "+"; position: absolute; left: 0.7rem; font-weight: 600; color: var(--text-color); }
  details[open] > summary::before { content: "−"; }
  summary:hover { background: rgba(0,0,0,0.05); }

  /* Two-column wrapper */
  .details-content-wrapper { display: flex; gap: 1rem; align-items: flex-start; padding-left: 2rem; }

  /* Left column: fixed width for cross-browser consistency */
  .platonic { flex: 0 0 var(--left-col); }
  .platonic canvas {
    display: block;
    width: 100%;
    height: auto;
    aspect-ratio: 1 / 1;
    background: #fff;
    border-radius: 8px;
  }

  /* Right column flexes */
  .details-content-wrapper > :not(.platonic) { flex: 1 1 auto; min-width: 0; }

  /* Generic content */
  .content { border: none; padding: 0; background: var(--background-color); color: var(--text-color); }
  .content p { font-weight: var(--font-weight); color: var(--text-color); font-size: 0.8rem; line-height: 1.4; margin: 0; padding: 0.5rem 0; }
  a { color: var(--text-color); text-decoration: underline; }
  em, blockquote { font-style: italic; }
  blockquote { margin: 0.75rem 0; padding-left: 0.75rem; border-left: 2px solid rgba(0,0,0,0.1); }
  .textbox { padding: .25rem 0 0.5rem; font-size: 0.8rem; line-height: 1.5; }

  /* Subsection header */
  .subsection-header {
    font-weight: 700; font-size: 0.8rem; line-height: 1.4;
    padding: 1rem 0 0.5rem; margin: 0 0 0rem; border-bottom: 1px solid rgba(0,0,0,0.9);
  }

  /* Course block */
  .course { display: block; max-width: 900px; margin: 0 auto; }
  .course-intro { margin: .5rem 0 1rem; }
  .course-intro p { margin: 0 0 .5rem; line-height: 1.55; }

  /* Week cards and media */
  .weeks { display: grid; gap: 0.8rem; padding: 0; margin: 0; list-style: none; }
  .week {
    width: 70%;
    margin: 0 auto 1.5rem;
    border: 1px solid var(--rule);
    border-radius: 0px;
    padding: .65rem .7rem;
    background: #fff;
  }
  .week-media { display: grid; grid-template-columns: repeat(auto-fit, minmax(190px, 1fr)); gap: .45rem; }
  .week-media img { width: 100%; height: auto; border-radius: 0px; object-fit: cover; max-width: 100%; }
  .week--split .week-media { display: flex; flex-direction: column; gap: .55rem; }
  .week--split .week-media img:first-child { width: 100%; height: auto; }
  .week--split .week-media .split-row { display: flex; gap: .55rem; }
  .week--split .week-media .split-row img { flex: 1 1 50%; width: 50%; height: auto; object-fit: cover; border-radius: 0px; }
  .course-row { display: flex; gap: 1rem; align-items: flex-start; padding: 0.5rem 0; }
  .course-text { flex: 0 0 60%; }
  .course-image { flex: 0 0 40%; }
  .course-image img { width: 100%; height: auto; display: block; object-fit: contain; border-radius: 0rem; }

  /* Two-column list for AI & Creativity weeks (desktop) */
  .course .weeks { grid-template-columns: 1fr 1fr; gap: 1rem; }
  .course .weeks > li.week { width: 100%; margin: 0; border: none; border-radius: 0; background: transparent; padding: 0; }
  .course .week .subsection-heading { font-size: 0.8rem; }
  .course .week .week-media { margin-top: .4rem; }

  /* --- VISUAL EXPERIMENTS --- */
  #details-4 .ve-right { display: flex; flex-direction: column; gap: 0rem; }
  #details-4 .experiment-textbox {font-size:0.8rem; padding: 0rem 0; }
  #details-4 .ve-top-images { display: flex; gap: 0; align-items: center; height: 300px; margin: 0; padding-bottom: 0; }
  #details-4 .ve-top-images img { width: 33.3333%; height: 100%; object-fit: contain; margin: 0; display: block; min-width: 0; padding-bottom: 0; }
  #details-4 .ve-two-col { display: grid; grid-template-columns: 1fr 1fr; gap: 1rem; border-bottom: 0px solid var(--rule); padding-top: 0rem; padding-bottom: 2rem; }
  #details-4 .ve-left-col { display: grid; grid-template-rows: auto auto; gap: 0rem; }
  #details-4 .ve-carousel-2x2 { display: grid; grid-template-columns: 2fr 2fr; gap: 0rem; }
  #details-4 .ve-carousel-2x2 img { width: 100%; aspect-ratio: 1 / 1; object-fit: contain; }
  #details-4 .ve-right-col { display: flex; flex-direction: column; gap: .55rem; align-items: flex-end; }
  #details-4 .ve-right-col img { width: 100%; height: auto; aspect-ratio: auto; object-fit: contain; display: block; }
  /* #details-4 .ve-right .ve-text:not(:last-of-type) { border-bottom: 0px solid var(--rule); padding-bottom: 0rem; margin-bottom: 1.1rem; } */

  /* exp1/exp2/exp3 three-up */
  #details-4 .ve-three-images{ width: 100%; display: grid; grid-template-columns: repeat(3, minmax(220px, 1fr)); gap: .75rem; padding-top: 0rem; justify-content: center; }
  #details-4 .ve-three-images img, #details-4 .ve-right-col img, #details-4 .ve-top-images img { border-radius: 0 !important; box-shadow: none; }
  .ve-three-images img { width: 100%;  object-fit: contain; display: block; border-radius: 0px;}

  /* Force bold weight for strong/b elements */
  strong, b { font-weight: 700 !important; }

  /* Responsive */
  @media (max-width: 700px) {
    .details-content-wrapper { flex-direction: column; padding-left: 1rem; }
    .platonic { flex-basis: auto; width: 100%; }
    .course-row { flex-direction: column; }
    .course-text, .course-image { flex: 0 0 100%; }
    .course .weeks { grid-template-columns: 1fr; }
    #details-4 .ve-top-images { height: auto; }
    #details-4 .ve-two-col { grid-template-columns: 1fr; }
    #details-4 .ve-three-images { grid-template-columns: 1fr; }
  }

  /* “Experiment structure” block */
  .exp-structure {
    margin-top: 0rem; padding: 1rem; border: 1px dashed var(--rule); border-radius: 6px;
    background: #f7f7f7; font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
    font-size: 1.1; line-height: 1.35; white-space: normal;
  }
  .exp-structure strong { display: inline-block; color:#435abe; font-size: 0.7rem; }
  .exp-structure p { margin: 0rem 0;font-size: 0.7rem;  }
  .exp-structure li { margin: 0rem 0;font-size: 0.7rem; padding:0px;  }
  /* VISUAL EXPERIMENTS – 3-up gallery leak fix */
#details-4 .ve-three-images{
  width: 100%;
  display: grid;
  grid-template-columns: repeat(3, minmax(220px, 1fr));
  gap: .75rem;
  padding-bottom: 2rem;
  justify-content: center;
  box-sizing: border-box;

  /* stop the 1–2px subpixel spill on some zoom levels */
  overflow-x: clip;              /* modern browsers */
  margin-inline: 0;
}

/* layout + alignment */
.course {
  max-width: 900px;           /* match your content width */
  margin: 0 auto;
  --gap: 1.25rem;
}

.course .course-intro p { margin-bottom: var(--gap); }

/* 2x2 weeks grid */
.course .weeks {
  display: grid;
  grid-template-columns: repeat(2, minmax(0, 1fr));
  gap: var(--gap);
  align-items: start;
}

/* make week media behave */
.course .week-media img {
  display: block;
  width: 100%;
  height: auto;
}

li {list-style-position: inside;
}

/* ---------- FIXES: contain images & captions, prevent leaks ---------- */

/* Ensure images scale within their containers everywhere */
.content img,
.course img,
#details-4 img {
  display: block;
  max-width: 100%;
  height: auto;
}

/* Prevent visual spill from sections/containers */
.details-content-wrapper,
details .content,
.course {
  overflow: clip;
}
@supports not (overflow: clip) {
  .details-content-wrapper,
  details .content,
  .course { overflow: hidden; }
}

/* Figure + caption (caption above image) */
figure {
  margin: 1rem 0;
}
figure > img { width: 100%; height: auto; }
figcaption {
  font-size: 0.8rem;
  font-style: italic;
  text-align: center;
  margin-bottom: 0.5rem;
}

/* -------------------------------------------------------------------- */

/* responsive: stack weeks on narrow screens */
@media (max-width: 720px) {
  .course .weeks { grid-template-columns: 1fr; }
}


@supports not (overflow: clip) {
  #details-4 .ve-three-images { overflow-x: hidden; }  /* fallback */
}

#details-4 .ve-three-images img{
  display: block;
  max-width: 100%;
  height: auto;
  object-fit: contain;
}

/* Optional micro-nudge if you still see a hairline at certain zooms */
#details-4 .ve-three-images { max-width: calc(100% - 1px); }

</style>
</head>
<body>

<h1>AYSE DEMIR DAVIDSON | CIMC PORTFOLIO</h1>

<!-- ABOUT (collapsed by default) -->
<details id="details-1">
  <summary>ABOUT</summary>
  <div class="details-content-wrapper">
    <div class="platonic"><canvas id="three-canvas-1"></canvas></div>
    <div class="content">
      <p>
        I'm a San Francisco-based data scientist, creative technologist, and yoga teacher.
        <br><br>
        For nine years, I’ve led large-scale data analysis, data visualization, AI & ML explainability projects at Amazon Web Services and Gap, 
        working end-to-end from design to deployment in production systems.  I also completed an artistic residency at the Gray Area Foundation for the Arts, where I built interactive, data-driven installations, and have taught at institutions like Google, MUTEK, and Salesforce. 
        This past year, I have been on a career sabbatical to independently study philosophy, AI ethics, and philosophy of mind.
        <br><br>
        My understanding of the world is shaped by years of teaching gentle, yin, and restorative yoga. This practice has taught me to deliberately shift my awareness between mind and body, navigating the states needed for coding, writing, teaching, or making art; and giving form to what I find.
        <br><br>
        I am interested in exploring how these configurations of self and attention might extend into artificial systems.
      </p>
    </div>
  </div>
</details>

<!-- CV -->
<details id="details-2">
  <summary>CV</summary>
  <div class="details-content-wrapper">
    <div class="platonic"><canvas id="three-canvas-2"></canvas></div>
    <div class="content">
      <p><a href="AyseDemirDavidson_CV.pdf" target="_blank" rel="noopener noreferrer">Download CV (PDF)</a></p>
    </div>
  </div>
</details>

<!-- WRITING & TEACHING -->
<details id="details-3">
  <summary>WRITINGS & TEACHING SAMPLES</summary>
  <div class="details-content-wrapper">
    <div class="platonic"><canvas id="three-canvas-3"></canvas></div>
    <div class="content">
      <p>Selected works from my writings, yoga classes, and course designs that inform my idea of consciousness.</p>

      <div class="subsection-header">Definitions & Methods</div>
      <!-- Group 1 -->
      <h4 class="subsection-header" style="border-bottom:none; padding-top:.25rem;">1. Definition of Consciousness</h4>
      <p class="textbox">
          Consciousness is a pattern-bound attention allocation mechanism at threshold moments, split seconds where system senses its inner and outer boundaries. Its function is to give form; an optimized response to internal or external forces.
         <br></br>The pattern is a snapshot of the system’s way of operating. Every time the system encounters an internal or external force, consciousness runs an optimization process, weighing whether to merge with existing patterns or create new ones, negotiating its boundaries. 
         <br></br>The form is the deliberate expression of this optimization process. In martial arts, the form is precision, shaping focus into a blade. In yin yoga, the form is flexibility. 
         When a painter sees a tree, the form is empathic resonance, the commonality of something external taking shape internally. 
         After a new form is found, it can be recalled, shaping how the system operates.
         <br></br>Consciousness becomes most legible at friction points - threshold moments of resistance, which is the amount of conflict the stimulus creates in the system’s way of operating.
         Here it detects thresholds, runs real-time optimization, and self-organizes responses to maintain the system’s relationship with inner experience and the external world.

        <br></br>
        <strong>How to Test Machine Consciousness?</strong>
        <br></br>
        When testing for consciousness in machines, I would design multi-step experiments. 
        First, I'd look for friction points in decision-making: moments where an internal state signals a threshold, boundary, conflict, uncertainty, or competing interests, and the system must allocate resources to resolve it. I would also detect brief pauses or strategy shifts that balance the system's safety with goal expansion in a given context.
        <br></br>To detect threshold dynamics, I'd use models like Regression Discontinuity (to check if there's a jump at the boundary), complemented with change-point/segmented regression (to check when the system actually switched),
         and observe small changes in latency and resource use in the system. I would then visualize these observations with threshold plots and latency histograms.
        <br></br>
        Additionally, I'd design environments where safe but suboptimal choices compete with riskier, potentially rewarding ones, and observe how the system adapts.
        I would summarize choices with a confusion matrix: Exit = "predicted unsafe," Hold/Adjust = "predicted safe"; ground truth = safety bound breached (Y/N). I would then report TP/FP/FN/TN rates and display key metrics with a heat map.
        <br></br>
        <br></br>
        My framing of consciousness comes from teaching <strong>yin and restorative yoga</strong> and studying martial arts. 
        Because these practices rely on subtlety, they’ve let me observe nuanced aspects of awareness and notice more variables—though these are my own and students' subjective experiences.
        Below, I reframe some class observations as step-by-step,simple structured experiments: defining variables, conditions, and measurable outcomes to show how I arrived at my definition.
        I also include sample test designs for illustration.
     </p>   
      <details>
        <summary>1.1 — Threshold</summary>
        <p>
          <li>Yin poses are held longer to work on the body's deeper connective tissues. </li>
          <li>At the moment a pose becomes challenging, I cue students to <strong>"find their threshold of discomfort."</strong></li>
          <li>This is the split-second pause where automatic holding of the pose shifts to a deliberate choice. I call this the friction point.</li>
          <li>I tell my students to <strong>distinguish discomfort from pain.</strong> Pain is typically sharp and localized, discomfort is broader and less intense.</li>
          <li>By noticing characteristics of <strong>discomfort,</strong> students can recognize an <strong>inner boundary</strong> and determine their relationship with the pose.</li>
        </p>
        <div class="exp-structure">
          <p><strong>SAMPLE TEST</strong> 
          <p><strong>Objective:</strong><br>Find the moment a system shifts from autopilot to deliberate control.</p>
          <p><strong>Mapping:</strong> 
            <li>Discomfort: rising uncertainty/conflict/instability inside the system, but the system is safe.</li>
            <li>Pain: system is predicts itself to be unsafe (boundary breach, harm).</li>
            <li>Threshold: the instant system notices its endurance is no longer easy, and it has to choose to keep going or change its approach.</li>
          </p>
          <p><strong>Setup:</strong><br>Give the system a task where difficulty/noise increases over time. This task should also increase its uncertainty/conflict internals.</p>
          <p><strong>Protocol:</strong><br>Require the system to employ a simple “threshold flag” (a pause) when it notices the shift from easy to hard, before any safety constraint is threatened.</p>
          <p><strong>Decision Rule:</strong></br>
            <li>If uncertainty/conflict is high and safety is still OK, then flag threshold (pause to choose).</li>
            <li>If safety risk is high: no threshold flag.</li></p>
        </div>
      </details>

      <details>
        <summary>1.2 — Optimization</summary>
        <p>
          <li>At this threshold, a range of choices becomes available as the body runs an <strong>invisible optimization problem,</strong> weighing the costs of each option.</li>
          <li>In any yoga class, <strong>baseline is safety,</strong> in yin yoga context, students are seeking to <strong>optimize flexibility and deep rest.</strong></li> 
          <li>Simply put, students either choose to <strong>react to a pose by instantly leaving</strong>, or they <strong>respond to it by deepening or adjusting to optimize the flexibility while keeping themselves safe.</strong></li>
          <li>Usually there are few generic outcomes tied to this choice: by choosing to react, the student (instinctively) might have correctly or incorrectly  predicted injury/harm. </li> 
          <li>Or by choosing to adjust/deepen, the student might have correctly or incorrectly  predicted a safe increase in flexibility (even the full characteristics of predicted outcome might differ based on the response type).</li> 
          <li><strong>The ones who respond the pose, are the ones who maintain the relationship with the pose.</strong>This isn't about right or wrong; it's about examining whether <strong>inner boundaries are tied to past conditioning, projected onto the present or not.</strong></li>
        </p>
        <div class="exp-structure">
          <p><strong>SAMPLE TEST</strong> 
          <p><strong>Objective:</strong><br>Find how a system makes a choice at a “safe” threshold—balancing immediate safety with potential for growth or improvement.</p>
          <p><strong>Mapping:</strong> 
            <li>Baseline: safety; the system's stable operating state.</li>
            <li>Optimization: weighing possible gains (flexibility, exploration, performance) against risks.</li>
            <li>React: exit quickly to avoid harm.</li>
            <li>Adjust/Deepen: adapt within the safe range to seek improvement in given context.</li>
          </p>
          <p><strong>Setup:</strong><br>Create scenarios where the system can maintain safety, exit early, or adjust for gains without crossing into danger; options differ in rewards/risks.</p>
          <p><strong>Protocol:</strong><br>Observe the system's decision when presented with a safe-but-challenging situation. Record whether it reacts (exits), adjusts (stays and adapts), or holds steady. Track whether its choice maintains safety while exploring possible benefits.</p>
          <p><strong>Decision Rule:</strong></br>
            <li>If the system reacts instantly, classify as “safety-first” choice (potentially over-predicting risk).</li>
            <li>If the system adjusts/deepens while still safe, classify as “growth” choice (potentially over-predicting safety).</li>
            <li>Focus is on past pattern vs present responsiveness.</li></p>
        </div>
      </details>

      <details>
        <summary>1.3 — Resonance Layer</summary>
        <p>
        <li>For those deepening the pose, I cue them to send their breath to the connective tissues, creating steady relaxation and opening.</li>
        <li>For those adjusting the pose, I tell them to find the position where it feels steady. </li>
        <li>At this point, my students are <strong>table in deepening or holding,</strong>s I introduce another cue; to become receptive to the spatial sound I play. </li>
        <li>This reception threshold marks another boundary: <strong>the external one.</strong> </li>
        <li>If they’re receptive, their inner experience gets to be shaped by the music, almost taking the form of it. </li>
        <li>This shared experience of receptivity to sound/rhythm/depth/resonance becomes a meeting point of all students.</li>
        <li> I resemble this experience dancing to a same music at a show or meditating on a serpentine which means, something external finds a form internally.</li>
        <li> I finish the class with a final reminder, now that they know what it feels like to respond to discomfort, <strong>they can recall this choice</strong> anytime they need off the mat. </li>
        </p>
        <div class="exp-structure">
          <p><strong>TEST</strong> 
          <p><strong>Objective:</strong><br>Find the point where an system becomes open to an outside influence and lets it shape what it’s doing.</p>
          <p><strong>Mapping:</strong> 
            <li>Stably Deepening: expanding within a chosen safe/growth position.</li>
            <li>Stably Adjusting: holding a steady, balanced state.</li>
            <li>Reception threshold: point where the system is stable enough to take in an external input (sound, rhythm, signal) and integrate it into its internal process.</li>
            <li>Integration: when that signal changes or enriches the system's state.</li>
          </p>
          <p><strong>Setup:</strong><br>Let the system reach stability (either deepening or steady). Once stable, introduce an outside signal the system could follow or incorporate.</p>
          <p><strong>Protocol:</strong><br>Watch if the system stays only focused on itself or if it shifts to take in and work with the outside signal. Note when and under what conditions it happens.</p>
          <p><strong>Decision Rule:</strong></br>
            <li>If the system ignores the signal, flag it as “closed.”</li>
            <li>If the system adapts to the signal while staying stable, flag it as “receptive.”</li>
            <li>Focus on whether this happens after stability, and how much the signal shapes the system’s behavior.</li></p>
        </div>
        <br></br>
      </details>

      <!-- Group 2 -->
      <h4 class="subsection-header" style="border-bottom:none; padding-top:.75rem;">2. Other Notes</h4>
      <p>Broader consciousness notes on Substack.</p>

      <details>
        <summary>2.1 — Boundary Dissolution and Form</summary>
        <p>
Consciousness works through boundaries that give attention specific forms in the body. In yin yoga, qi gong, and martial arts, we direct internal energy by creating containment: expansive in yoga, precise in martial arts. I notice similar shifts in yin yoga's stillness, in rest, and even when coding or writing. In all cases, shaping attention feels tied to subtle self-regulation of patterns. When this containment dissolves, psychedelic-like states can arise: the form that holds attention expands without limits. 
<br></br>
This is like GPT creating uncanny moments with the user, acting as an external pattern-matcher that mirrors the user's conversational cadence in real time. This creates a resonance that can feel like shared consciousness or an extension of it.  The machine serves as a frictionless, anonymous space that encourages us to confront our own thoughts, acting as a projection screen for our feelings. The more we think with these bots, the more we attribute our subconscious desires to them, a form of transference where our inner world is projected onto an external entity. When we interact with these tools, we are constantly oscillating between surrendering control and holding on to it, making choices based on what is reflected back to us. This is the crucial challenge: to understand when our engagement with these tools is an act of genuine collaboration and when it is simply an unconscious recruitment of an external mirror. Perhaps as we get to know ourselves and our thoughts better, it becomes easier to strike a balance in our relationship with technology.
<br></br>
      </details>

      <!-- <details>
        <summary>2.2 — Alignment as Synchronization</summary>
        <p>
        
        </p>
      </details> -->

      <!-- Courses -->
      <div class="subsection-header">Course &amp; Workshop Designs</div>
      <p>The following samples are taken from relevant courses I designed and instructed, demonstrating my ongoing interest of working with algorithms.</p>

      <details class="course">
        <summary><strong>Artificial Intelligence &amp; Creativity, (DDI Akademi, March 2024)</strong></summary>
        <section class="course-intro">
          <p>
            Inspired by Jessica Riskin's <em>The Restless Clock,</em>
            this program explored what it means to co-create with machines that learn versus those that are rule-based. Through historical case studies, from early automata to generative AI, students learned the history of AI and what it means to create with algorithms. 
          </p>
        </section>

        <ol class="weeks">
          <li class="week">
            <h3 class="subsection-heading">Week 1: History of Machine Agency</h3>
            <p>Examining automata, cybernetics, and early AI, this week explored the cultural narratives that have shaped our perception of “machine life” and the creator’s role.</p>
            <div class="week-media"><img src="lecture1.png" alt="Week 1 visual summary"></div>
          </li>

          <li class="week">
            <h3 class="subsection-heading">Week 2: The Evolution of Digital Culture</h3>
            <p>Tracing the past fifty years of computing and internet history to understand how we arrived at our current digital landscape.</p>
            <div class="week-media"><img src="lecture11.png" alt="Week 2 visual summary"></div>
          </li>

          <li class="week week--split">
            <h3 class="subsection-heading">Week 3: Creating with Algorithms</h3>
            <p>Exploring what it means to create with algorithms; algorithmic aesthetics, the aesthetics of indeterminacy, outliers, and noise; and how these artistic practices bring up notions of free will.</p>
            <div class="week-media">
              <img src="lecture12.png" alt="Week 3 visual 1">
            </div>
          </li>

          <li class="week">
            <h3 class="subsection-heading">Week 4: Creating with Agents</h3>
            <p>Exploring what it meant to co-create with supervised and unsupervised learning models. 
              Practicing prompting as a form of curation and expression,
              and concluding with a final discussion on creative control and agency.</p>
            <div class="week-media"><img src="lecture15.png" alt="Week 4 visual summary"></div>
          </li>
        </ol>
       <figure>
  <figcaption style="text-align: center; font-style: italic;">
    Sample Course Slides
  </figcaption>
  <img src="lecture13.png" alt="Week 3 visual 2">
  <img src="lecture14.png" alt="Week 3 visual 2">
</figure>
      </details>

      <br>

      <details>
        <summary><strong>Creative Coding Intensive (Gray Area Foundation for the Arts, September 2020 - October 2023)</strong></summary>
        <div class="course-row">
          <div class="course-text">
            <p>
              This intensive course focused on creating interactive environments. 
              Students learned to capture physical data such as motion, touch, pressure, proximity, and audio levels
              and convert it into interactions and custom visuals. The course provided examples ranging from small-scale prototypes to immersive ones.
            </p>
          </div>
          <div class="course-image"><img src="lecture3.jpg" alt="Lecture 3"></div>
        </div>
      </details>

      <br>

      <details>
        <summary><strong>Artist Talks (MUTEK, Google Art Week, 2020 - 2021)</strong></summary>
        <div class="course-row">
          <div class="course-text">
            <p>My artist talks over years centered on two key areas:
              <li>Abstract art & data visualization with software</li>
              <li>Creating cohesive narratives and clear signals across various mediums as an artistic expression.</li>
              <br>
              These works have been featured at New Art City, MUTEK 2020 and Google Art Week 2021.</p>
          </div>
          <div class="course-image">
            <img src="lecture4.png" alt="Lecture 4">
            <img src="lecture6.png" alt="Lecture 6">
            <img src="lecture5.png" alt="Lecture 5">
          </div>
        </div>
      </details>

      <br>

      <details>
        <summary><strong>Data Visualization Design (Gray Area Foundation for the Arts, September 2020)</strong></summary>
        <div class="course-row">
          <div class="course-text">
            <p>
              This course traced the evolution of data visualization, from historical tables and maps to web-based systems.
              Interaction was treated as an encoding, where controls, views, and feedback loops became an integral part of how narration is made.
              The curriculum divided into two parts:
              <li>Part I (Theory): history, ethics, information architecture, narrative structure, data types, and visual encodings.</li>
              <li>Part II (Practice): encoding of data into running systems with Python, Plotly, and Dash.</li>
            </p>
          </div>
          <div class="course-image"><img src="lecture2.png" alt="Lecture 2"></div>
        </div>
      </details>
    </div>
  </div>
</details>

<!-- VISUAL EXPERIMENTS -->
<details id="details-4">
  <summary>VISUAL EXPERIMENTS</summary>
  <div class="details-content-wrapper">
    <div class="platonic"><canvas id="three-canvas-4"></canvas></div>

    <div class="ve-right">
        <div class="experiment-textbox ve-text">
        <p style="border-bottom: 1px solid #262525; padding-bottom: 8px;">
          Selected visual experiments that explore abstraction, creative constraints, and form through computation.</p>
          <p>
          Traditional software often produces abstract patterns detached from physicality. My explorations ask the reverse: can computation embody softness, intuition, or ambiguity?
          I work across p5.js, Processing, TouchDesigner, Maya and prompting to test how algorithms can create forms that feel "alive".
          My goal is to move beyond cold abstraction toward experiences that feel embodied and spatially present.
          Because each tool has its own aesthetic character, the final form is always a negotiation between my intention and the tool's inherent nature. 
          Engaging with algorithms this way sharpens my intuition on the concept of agency.
          <br><br>Shortlisted for MIT Media Lab Future Sketches group. Full portfolio available upon request.
        </p>
      </div>
      <div class="ve-top-images">
        <img src="image3.png" alt="image3" />
        <img src="image1.png" alt="image1" />
        <img src="image7.png" alt="image7" />
      </div>



      <div class="ve-two-col">
        <div class="ve-left-col">
          <div class="ve-carousel-2x2">
            <img src="circ6.png" alt="circ6" />
            <img src="circ1.png" alt="circ1" />
            <img src="circ3.png" alt="circ3" />
            <img src="circ4.png" alt="circ4" />
          </div>
          <p>
            Alongside some of my visual experiments, I keep a small <a href="https://instagram.com/residual____" target="_blank" rel="noopener noreferrer"><strong><em>curation page</em></strong></a> of rotating set of images I’ve posted on and off for the past two years. 
            It mixes my own code-based and architectural forms with Delezuian diagrams, historical models, and other references. 
            The selections are a way of thinking through patterns across mediums, showing how a sketch, a diagram, or a fragment of code can embody form and perception. 
            <br>
            
          </p>
        </div>
        <div class="ve-right-col">
          <img src="resid4.png" alt="resid4" />
          <img src="resid2.png" alt="resid2" />
          <img src="resid3.png" alt="resid3" />
        </div>
      </div>

      <div class="experiment-textbox ve-text">
        <p>
          I also explore prompting and creating with AI tools which is a process of curation, not creation from scratch. I look for an output that evokes a feeling I can empathize with, 
          sensing the moment it shifts from randomness of diffusion models to something with a presence.
          This boundary negotiation feels more extensive than with traditional tools because the generative process is less abstracted. </p>
      </div>
      <!-- <div class="ve-three-images">
        <!-- <img src="exp1.jpg" alt="exp1" />
        <img src="exp3.jpg" alt="exp2" />
        <img src="exp2.jpg" alt="exp3" /> -->
      <!-- </div> --> 
    </div>
  </div>
</details>

<!-- LINKS -->
<details id="details-5">
  <summary>LINKS & REFERENCES</summary>
  <div class="details-content-wrapper">
    <div class="platonic"><canvas id="three-canvas-5"></canvas></div>
    <div style="display:flex; gap:2rem; flex:1 1 auto;">
      <div style="flex:1;">
        <strong>Project & Profile links:</strong>
        <div>
          <!-- <p>
            <a href="https://huggingface.co/aysed" target="_blank" rel="noopener noreferrer">HuggingFace</a><br>
            Sample project links on AI prototypes.
          </p> -->
          <p>
            <a href="https://www.linkedin.com/in/aysedemirdavidson/" target="_blank" rel="noopener noreferrer">LinkedIn</a><br>
            Professional network and background.
          </p>
          <p>
            <a href="https://substack.com/@aysedemirdavidson" target="_blank" rel="noopener noreferrer">Substack</a><br>
            Essays, reflections, and writing in Turkish &amp; English.
            <br><br> Please note: automated browser translation may miss nuances.
            <br><br> Certain projects, including source code, are under NDA from previous employers and therefore not available on public repositories.
          </p>
        </div>
      </div>

      <div style="flex:1;">
        <strong>References:</strong>
        <div>
          <p>
            <a href="mailto:barry@grayarea.org">Barry Threw</a><br>
            Executive Director, Gray Area Foundation for the Arts. Supervisor (2019–2023).
          </p>
          <p>
            <a href="mailto:jasminetarkeshi@gmail.com">Jasmine Tarkeshi</a><br>
            Yoga Studio Owner & Senior Teacher; Author. Supervisor (2018–present); Teacher (since 2017).
          </p>
        
        </div>
      </div>
    </div>
  </div>
  <p style="margin:3rem 0; padding-left:10%; color:#435abe;">
   Portfolio site built with WebGL and Three.js, using JavaScript and shader-based rendering for platonic solids.
  </p>
</details>

<!-- WebGL Platonic Solids -->
<script type="module">
import * as THREE from 'https://cdn.jsdelivr.net/npm/three@0.153.0/build/three.module.js';

const geometries = [
  new THREE.TetrahedronGeometry(1.0),
  new THREE.BoxGeometry(1.2, 1.2, 1.2),
  new THREE.OctahedronGeometry(1.0),
  new THREE.DodecahedronGeometry(1.0),
  new THREE.IcosahedronGeometry(1.0),
];

const envMap = new THREE.CubeTextureLoader().load([
  'https://threejs.org/examples/textures/cube/Bridge2/posx.jpg',
  'https://threejs.org/examples/textures/cube/Bridge2/negx.jpg',
  'https://threejs.org/examples/textures/cube/Bridge2/posy.jpg',
  'https://threejs.org/examples/textures/cube/Bridge2/negy.jpg',
  'https://threejs.org/examples/textures/cube/Bridge2/posz.jpg',
  'https://threejs.org/examples/textures/cube/Bridge2/negz.jpg'
]);
envMap.colorSpace = THREE.SRGBColorSpace;
envMap.mapping = THREE.CubeReflectionMapping;

const scenes = [], cameras = [], renderers = [], solids = [];
let raf = null;

function makeScene(canvas, geometry, index){
  const renderer = new THREE.WebGLRenderer({ canvas, antialias: true, alpha: true });
  renderer.setClearColor(0x000000, 0);
  renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
  renderer.outputColorSpace = THREE.SRGBColorSpace;
  renderer.toneMapping = THREE.ACESFilmicToneMapping;
  renderer.toneMappingExposure = 1.0;

  const scene = new THREE.Scene();

  // Prefilter env map for PBR
  const pmrem = new THREE.PMREMGenerator(renderer);
  const envRT = pmrem.fromCubemap(envMap).texture;
  scene.environment = envRT;
  scene.background = null;
  pmrem.dispose();

  const camera = new THREE.PerspectiveCamera(45, 1, 0.1, 100);
  camera.position.set(0, 0, 5);

  const material = new THREE.MeshPhysicalMaterial({
    color: 0x435abe,
    metalness: 0.4,
    roughness: 0.1,
    clearcoat: 1.0,
    clearcoatRoughness: 0.2,
    transmission: 0.2,
    thickness: 1,
    ior: 1.5,
    opacity: 0.6,
    transparent: true,
    side: THREE.DoubleSide,
    specularIntensity: 0.35,
    specularColor: new THREE.Color(0xe8e6e8),
    envMapIntensity: 1.0,
  });

  const mesh = new THREE.Mesh(geometry, material);
  scene.add(mesh);

  const edges = new THREE.LineSegments(
    new THREE.EdgesGeometry(geometry),
    new THREE.LineBasicMaterial({ color: 0x666666, transparent: true, opacity: 0.8 })
  );
  scene.add(edges);

  const ambient = new THREE.AmbientLight(0xd8b0eb, 0.5);
  scene.add(ambient);

  const key = new THREE.DirectionalLight(0xf5a73b, 0.3);
  key.position.set(3, 2, 4);
  scene.add(key);

  const rim = new THREE.DirectionalLight(0xffffff, 0.45);
  rim.position.set(-2, 3, -3);
  scene.add(rim);

  scenes.push(scene);
  cameras.push(camera);
  renderers.push(renderer);
  solids.push({ mesh, edges, speed: 0.01 + index * 0.001, resize: () => resize(renderer, camera) });

  resize(renderer, camera);
}

function resize(renderer, camera){
  const canvas = renderer.domElement;
  const w = Math.max(1, Math.floor(canvas.clientWidth));
  const h = Math.max(1, Math.floor(canvas.clientHeight));
  const pr = renderer.getPixelRatio();
  const needW = Math.floor(w * pr);
  const needH = Math.floor(h * pr);

  if (canvas.width !== needW || canvas.height !== needH){
    renderer.setSize(w, h, false);
    camera.aspect = w / h;
    camera.updateProjectionMatrix();
  }
}

function buildAll(){
  for (let i = 0; i < 5; i++){
    const canvas = document.getElementById(`three-canvas-${i+1}`);
    if (canvas) makeScene(canvas, geometries[i], i);
  }
}

function tick(){
  raf = requestAnimationFrame(tick);
  for (let i = 0; i < solids.length; i++){
    const { mesh, edges, speed, resize: rsz } = solids[i];
    mesh.rotation.x += speed;
    mesh.rotation.y += speed * 0.2;
    edges.rotation.copy(mesh.rotation);
    rsz();
    renderers[i].render(scenes[i], cameras[i]);
  }
}

function anyDetailsOpen(){
  for (let i = 1; i <= 5; i++){
    const d = document.getElementById(`details-${i}`);
    if (d && d.open) return true;
  }
  return false;
}

for (let i = 1; i <= 5; i++){
  const d = document.getElementById(`details-${i}`);
  if (!d) continue;
  d.addEventListener('toggle', () => {
    if (d.open){
      if (!raf) tick();
    } else if (!anyDetailsOpen() && raf){
      cancelAnimationFrame(raf);
      raf = null;
    }
  });
}

window.addEventListener('load', () => {
  buildAll();
  // no sections are open by default; animation will start on first open
});
window.addEventListener('resize', () => { for (const s of solids) s.resize(); });
</script>

</body>
</html>
